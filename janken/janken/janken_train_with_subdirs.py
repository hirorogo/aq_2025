import os
import shutil
import random
import tensorflow as tf
import matplotlib.pyplot as plt
from pathlib import Path
import numpy as np


# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼è¨­å®š
target_size = 224
batch_size = 16  # GPU ãƒ¡ãƒ¢ãƒªä¸è¶³å¯¾ç­–: 32â†’16ã«å‰Šæ¸›
epochs = 100  # æœ€å¤§100ã‚¨ãƒãƒƒã‚¯ (EarlyStoppingã§è‡ªå‹•èª¿æ•´)
learning_rate = 0.0001

# ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰é¸æŠã™ã‚‹ç”»åƒæ•° (Noneã§ã™ã¹ã¦ä½¿ç”¨)
MAX_SUBDIR_IMAGES = None

preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)


# ============================================================
# ã‚«ã‚¹ã‚¿ãƒ ãƒ–ãƒ¬å¯¾ç­–ãƒ¬ã‚¤ãƒ¤ãƒ¼
# ============================================================

class RandomMotionBlur(tf.keras.layers.Layer):
    """
    æ‰‹ãƒ–ãƒ¬ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ–ãƒ©ãƒ¼ãƒ¬ã‚¤ãƒ¤ãƒ¼
    æ¨ªæ–¹å‘ãƒ»ç¸¦æ–¹å‘ãƒ»æ–œã‚æ–¹å‘ã®ãƒ–ãƒ¬ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é©ç”¨
    """
    def __init__(self, max_kernel_size=7, **kwargs):
        super().__init__(**kwargs)
        self.max_kernel_size = max_kernel_size
    
    def call(self, images, training=None):
        if not training:
            return images
        
        # ãƒãƒƒãƒå†…ã®å„ç”»åƒã«å¯¾ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ–ãƒ¬ã‚’é©ç”¨
        def apply_blur(image):
            # 50%ã®ç¢ºç‡ã§ãƒ–ãƒ©ãƒ¼ã‚’é©ç”¨
            if tf.random.uniform(()) > 0.5:
                return image
            
            # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º (3, 5, 7)
            kernel_size = tf.random.uniform((), 3, self.max_kernel_size + 1, dtype=tf.int32)
            kernel_size = kernel_size // 2 * 2 + 1  # å¥‡æ•°ã«èª¿æ•´
            
            # ãƒ©ãƒ³ãƒ€ãƒ ãªæ–¹å‘ (0: æ¨ª, 1: ç¸¦, 2: æ–œã‚å³, 3: æ–œã‚å·¦)
            direction = tf.random.uniform((), 0, 4, dtype=tf.int32)
            
            # OpenCVé¢¨ã®ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ–ãƒ©ãƒ¼ã‚’TensorFlowã§å®Ÿè£…
            # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ã§ä»£ç”¨ï¼ˆæ‰‹ãƒ–ãƒ¬ã®è¿‘ä¼¼ï¼‰
            image = tf.image.resize(image, [224, 224])
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªå¹³å‡ãƒ–ãƒ©ãƒ¼ï¼ˆæ¨ªæ–¹å‘ã®ä¾‹ï¼‰
            # ã‚ˆã‚Šé«˜åº¦ãªå®Ÿè£…ã‚‚å¯èƒ½ã ãŒã€è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•
            return tf.cast(image, tf.float32)
        
        return images  # ç°¡æ˜“ç‰ˆ: GaussianNoiseã§ä»£ç”¨


class RandomDefocus(tf.keras.layers.Layer):
    """
    ãƒ”ãƒ³ã¼ã‘ï¼ˆãƒ‡ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ï¼‰ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    ã‚«ãƒ¡ãƒ©ã®ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ãŒåˆã£ã¦ã„ãªã„çŠ¶æ…‹ã‚’å†ç¾
    """
    def __init__(self, max_strength=0.3, **kwargs):
        super().__init__(**kwargs)
        self.max_strength = max_strength
    
    def call(self, images, training=None):
        if not training:
            return images
        
        # 30%ã®ç¢ºç‡ã§ãƒ‡ãƒ•ã‚©ãƒ¼ã‚«ã‚¹é©ç”¨
        if tf.random.uniform(()) > 0.3:
            return images
        
        # ãƒ©ãƒ³ãƒ€ãƒ ãªå¼·åº¦
        strength = tf.random.uniform((), 0, self.max_strength)
        
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ã¼ã‹ã—ã§è¿‘ä¼¼
        # å®Ÿè£…ç°¡ç•¥åŒ–ã®ãŸã‚ã€ãƒã‚¤ã‚ºè¿½åŠ ã§ä»£ç”¨
        noise = tf.random.normal(tf.shape(images), mean=0, stddev=strength * 10)
        return tf.clip_by_value(images + noise, 0, 255)


def create_merged_dataset(base_dir, max_subdir_images=MAX_SUBDIR_IMAGES):
    """
    å„ã‚¯ãƒ©ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ç”»åƒã¨ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ç”»åƒã‚’çµ±åˆã—ãŸ
    ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã™ã‚‹
    
    Args:
        base_dir: "img_train" ã¾ãŸã¯ "img_test"
        max_subdir_images: ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰é¸æŠã™ã‚‹æœ€å¤§ç”»åƒæ•°
    
    Returns:
        merged_dir: çµ±åˆã•ã‚ŒãŸä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
    """
    merged_dir = f"{base_dir}_merged"
    
    # æ—¢å­˜ã®ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Œã°å‰Šé™¤
    if os.path.exists(merged_dir):
        shutil.rmtree(merged_dir)
    
    os.makedirs(merged_dir, exist_ok=True)
    
    # å„ã‚¯ãƒ©ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†
    class_dirs = [d for d in os.listdir(base_dir) 
                  if os.path.isdir(os.path.join(base_dir, d))]
    
    for class_dir in class_dirs:
        source_class_path = os.path.join(base_dir, class_dir)
        target_class_path = os.path.join(merged_dir, class_dir)
        os.makedirs(target_class_path, exist_ok=True)
        
        # ã‚¯ãƒ©ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
        for file in os.listdir(source_class_path):
            file_path = os.path.join(source_class_path, file)
            if os.path.isfile(file_path):
                # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚³ãƒ”ãƒ¼
                if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):
                    shutil.copy2(file_path, os.path.join(target_class_path, file))
        
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
        for subdir in os.listdir(source_class_path):
            subdir_path = os.path.join(source_class_path, subdir)
            if os.path.isdir(subdir_path):
                # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
                subdir_images = []
                for file in os.listdir(subdir_path):
                    file_path = os.path.join(subdir_path, file)
                    if os.path.isfile(file_path):
                        if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):
                            subdir_images.append((file_path, file))
                
                # max_subdir_imagesãŒNoneã®å ´åˆã¯ã™ã¹ã¦ä½¿ç”¨ã€ãã‚Œä»¥å¤–ã¯ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
                if max_subdir_images is None or len(subdir_images) <= max_subdir_images:
                    print(f"  {class_dir}/{subdir}: {len(subdir_images)}æšã™ã¹ã¦ä½¿ç”¨")
                else:
                    print(f"  {class_dir}/{subdir}: {len(subdir_images)}æš â†’ {max_subdir_images}æšã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ")
                    subdir_images = random.sample(subdir_images, max_subdir_images)
                
                # é¸æŠã•ã‚ŒãŸç”»åƒã‚’ã‚³ãƒ”ãƒ¼
                for file_path, file in subdir_images:
                    new_filename = f"{subdir}_{file}"
                    shutil.copy2(file_path, os.path.join(target_class_path, new_filename))
    
    return merged_dir


def count_images(directory):
    """
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ç”»åƒæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦è¡¨ç¤º
    """
    print(f"\nğŸ“Š {directory} ã®ç”»åƒæ•°:")
    print("=" * 60)
    total = 0
    class_dirs = sorted([d for d in os.listdir(directory) 
                        if os.path.isdir(os.path.join(directory, d))])
    
    for class_dir in class_dirs:
        class_path = os.path.join(directory, class_dir)
        image_files = [f for f in os.listdir(class_path) 
                      if os.path.isfile(os.path.join(class_path, f)) and
                      f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif'))]
        count = len(image_files)
        total += count
        print(f"  {class_dir}: {count}æš")
    
    print(f"  åˆè¨ˆ: {total}æš")
    print("=" * 60)


def plot_result(history):
    """
    å…¨ã¦ã®å­¦ç¿’ãŒçµ‚äº†ã—ãŸå¾Œã«ã€historyã‚’å‚ç…§ã—ã¦ã€accuracyã¨lossã‚’ãã‚Œãã‚Œplotã™ã‚‹
    """
    # accuracy
    plt.figure()
    plt.plot(history.history["accuracy"], label="acc", marker=".")
    plt.plot(history.history["val_accuracy"], label="val_acc", marker=".")
    plt.xticks(ticks=range(0, epochs), labels=range(1, epochs+1))
    plt.grid()
    plt.legend(loc="best")
    plt.xlabel("epochs")
    plt.ylabel("accuracy")
    plt.savefig("mlp_graph_accuracy_with_subdirs.png")

    # loss
    plt.figure()
    plt.plot(history.history["loss"], label="loss", marker=".")
    plt.plot(history.history["val_loss"], label="val_loss", marker=".")
    plt.xticks(ticks=range(0, epochs), labels=range(1, epochs+1))
    plt.grid()
    plt.legend(loc="best")
    plt.xlabel("epochs")
    plt.ylabel("loss")
    plt.savefig("mlp_graph_loss_with_subdirs.png")


def _main():
    print("ğŸ”„ ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ä¸­...")
    
    # çµ±åˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    merged_train_dir = create_merged_dataset("img_train")
    merged_test_dir = create_merged_dataset("img_test")
    
    # ç”»åƒæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    count_images(merged_train_dir)
    count_images(merged_test_dir)
    
    print("\nğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...")
    
    # å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    train_ds = tf.keras.utils.image_dataset_from_directory(
        merged_train_dir,
        image_size=(target_size, target_size),
        batch_size=batch_size,
        label_mode="categorical",
        shuffle=True,
        seed=42
    )
    
    # è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    test_ds = tf.keras.utils.image_dataset_from_directory(
        merged_test_dir,
        image_size=(target_size, target_size),
        batch_size=batch_size,
        label_mode="categorical",
        shuffle=False
    )
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨ãƒ—ãƒªãƒ—ãƒ­ã‚»ãƒƒã‚·ãƒ³ã‚°ã‚’é©ç”¨
    # ğŸ† éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (æ¤œè¨¼ç²¾åº¦: 89.83%)
    # âš¡ ãƒ–ãƒ¬å¯¾ç­–å¼·åŒ–ç‰ˆ
    data_augmentation = tf.keras.Sequential([
        tf.keras.layers.RandomRotation(0.117),            # Â±42.3åº¦å›è»¢ (æœ€é©å€¤)
        tf.keras.layers.RandomZoom(0.021),                # Â±2.1%ã‚ºãƒ¼ãƒ  (æœ€å°é™)
        tf.keras.layers.RandomTranslation(0.094, 0.094),  # ä¸Šä¸‹å·¦å³9.4%ç§»å‹•
        # ç…§æ˜æ¡ä»¶ã®å¤‰åŒ–ã«å¯¾å¿œ (é‡è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿!)
        tf.keras.layers.RandomBrightness(0.447),          # æ˜ã‚‹ã•Â±44.7% (å¤§ãã‚ãŒæœ€é©)
        tf.keras.layers.RandomContrast(0.428),            # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆÂ±42.8% (å¤§ãã‚ãŒæœ€é©)
        # â˜…ãƒ–ãƒ¬ãƒ»ãƒœã‚±å¯¾ç­– (å¼·åŒ–ç‰ˆ)
        tf.keras.layers.GaussianNoise(0.130),             # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚º 13.0%
        RandomDefocus(max_strength=0.02),                 # ãƒ”ãƒ³ã¼ã‘ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    ], name='augmentation_with_blur')
    
    # å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«æ‹¡å¼µã¨ãƒ—ãƒªãƒ—ãƒ­ã‚»ãƒƒã‚·ãƒ³ã‚°ã‚’é©ç”¨
    train_ds = train_ds.map(
        lambda x, y: (data_augmentation(x, training=True), y),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    train_ds = train_ds.map(
        lambda x, y: (preprocessing_function(x), y),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)
    
    # è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãƒ—ãƒªãƒ—ãƒ­ã‚»ãƒƒã‚·ãƒ³ã‚°ã‚’é©ç”¨
    test_ds = test_ds.map(
        lambda x, y: (preprocessing_function(x), y),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    test_ds = test_ds.prefetch(tf.data.AUTOTUNE)

    print("\nğŸ—ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...")
    
    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=(target_size, target_size, 3),
        include_top=False,
        weights="imagenet"
    )
    x = base_model.output
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    x = tf.keras.layers.Dense(3, activation="softmax")(x)
    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)
    model.summary()

    # æœ€é©åŒ–é–¢æ•°ã€æå¤±é–¢æ•°ã€è¡¨ç¤ºæŒ‡æ¨™è¨­å®š
    model.compile(optimizer=optimizer,
                  loss="categorical_crossentropy",
                  metrics=["accuracy"])

    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
    callbacks = [
        # EarlyStopping: æ¤œè¨¼ç²¾åº¦ãŒæ”¹å–„ã—ãªããªã£ãŸã‚‰å­¦ç¿’ã‚’åœæ­¢
        tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy',        # æ¤œè¨¼ç²¾åº¦ã‚’ç›£è¦–
            patience=10,                   # 10ã‚¨ãƒãƒƒã‚¯æ”¹å–„ã—ãªã‘ã‚Œã°åœæ­¢
            restore_best_weights=True,     # æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¾©å…ƒ
            verbose=1,
            mode='max'                     # ç²¾åº¦ã¯é«˜ã„æ–¹ãŒè‰¯ã„
        ),
        # ReduceLROnPlateau: ç²¾åº¦ãŒåœæ»ã—ãŸã‚‰å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_accuracy',
            factor=0.5,                    # å­¦ç¿’ç‡ã‚’åŠåˆ†ã«
            patience=5,                    # 5ã‚¨ãƒãƒƒã‚¯æ”¹å–„ã—ãªã‘ã‚Œã°å®Ÿè¡Œ
            min_lr=1e-7,                   # æœ€å°å­¦ç¿’ç‡
            verbose=1,
            mode='max'
        ),
        # ModelCheckpoint: æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•ä¿å­˜
        tf.keras.callbacks.ModelCheckpoint(
            'best_model_checkpoint.keras',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1,
            mode='max'
        )
    ]

    print("\nğŸš€ å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
    print(f"  - æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
    print(f"  - ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
    print(f"  - å­¦ç¿’ç‡: {learning_rate}")
    print(f"  - EarlyStopping: æœ‰åŠ¹ (patience=10)")
    print(f"  - ReduceLROnPlateau: æœ‰åŠ¹ (patience=5)")
    print("=" * 60)
    
    # å­¦ç¿’é–‹å§‹
    history = model.fit(train_ds,
                        validation_data=test_ds,
                        epochs=epochs,
                        callbacks=callbacks,
                        verbose=2)

    print("\nğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ä¸­...")
    
    # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model.save("model_with_subdirs.keras", include_optimizer=False)
    print("âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: model_with_subdirs.keras")

    print("\nğŸ“Š å­¦ç¿’çµæœã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆä¸­...")
    
    # å­¦ç¿’éç¨‹ã®ã‚°ãƒ©ãƒ•ã‚’æç”»
    plot_result(history)
    print("âœ… ã‚°ãƒ©ãƒ•ä¿å­˜å®Œäº†:")
    print("  - mlp_graph_accuracy_with_subdirs.png")
    print("  - mlp_graph_loss_with_subdirs.png")
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    print("\nğŸ§¹ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
    if os.path.exists(merged_train_dir):
        shutil.rmtree(merged_train_dir)
    if os.path.exists(merged_test_dir):
        shutil.rmtree(merged_test_dir)
    print("âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ!")
    print("=" * 60)


if __name__ == "__main__":
    _main()
