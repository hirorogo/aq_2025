"""
ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–
ç„¼ããªã¾ã—æ³• + éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¢ç´¢
"""

import os
import shutil
import random
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from datetime import datetime
import json
import math


# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
target_size = 224
batch_size = 16  # GPU ãƒ¡ãƒ¢ãƒªä¸è¶³å¯¾ç­–: 32â†’16ã«å‰Šæ¸›
epochs = 15  # é«˜é€Ÿè©•ä¾¡ã®ãŸã‚å‰Šæ¸›
learning_rate = 0.0001

# æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
POPULATION_SIZE = 8          # éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é›†å›£ã‚µã‚¤ã‚º
GENERATIONS = 15             # ä¸–ä»£æ•°
SIMULATED_ANNEALING_TEMP = 1.0  # ç„¼ããªã¾ã—æ³•ã®åˆæœŸæ¸©åº¦
COOLING_RATE = 0.9           # å†·å´ç‡
ELITE_SIZE = 2               # ã‚¨ãƒªãƒ¼ãƒˆé¸æŠæ•°

preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input
optimizer_class = tf.keras.optimizers.Adam


class AugmentationParams:
    """ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, rotation=0.25, zoom=0.15, translation=0.1, 
                 brightness=0.3, contrast=0.3, noise=0.05):
        self.rotation = rotation
        self.zoom = zoom
        self.translation = translation
        self.brightness = brightness
        self.contrast = contrast
        self.noise = noise
        self.fitness = 0.0  # é©å¿œåº¦ï¼ˆæ¤œè¨¼ç²¾åº¦ï¼‰
        
    def to_dict(self):
        return {
            'rotation': self.rotation,
            'zoom': self.zoom,
            'translation': self.translation,
            'brightness': self.brightness,
            'contrast': self.contrast,
            'noise': self.noise,
            'fitness': self.fitness
        }
    
    def mutate(self, temperature=1.0):
        """çªç„¶å¤‰ç•° (ç„¼ããªã¾ã—æ³•ã®æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ã)"""
        params = AugmentationParams(
            rotation=self.rotation,
            zoom=self.zoom,
            translation=self.translation,
            brightness=self.brightness,
            contrast=self.contrast,
            noise=self.noise
        )
        
        # æ¸©åº¦ãŒé«˜ã„ã»ã©å¤§ããªå¤‰åŒ–
        mutation_strength = 0.1 * temperature
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«1-3å€‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´
        num_mutations = random.randint(1, 3)
        param_names = ['rotation', 'zoom', 'translation', 'brightness', 'contrast', 'noise']
        
        for _ in range(num_mutations):
            param = random.choice(param_names)
            current_value = getattr(params, param)
            
            # ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã§å¤‰æ›´
            delta = np.random.normal(0, mutation_strength)
            new_value = current_value + delta
            
            # ç¯„å›²åˆ¶é™
            if param == 'rotation':
                new_value = np.clip(new_value, 0.0, 0.5)  # 0-180åº¦
            elif param == 'zoom':
                new_value = np.clip(new_value, 0.0, 0.4)  # 0-40%
            elif param == 'translation':
                new_value = np.clip(new_value, 0.0, 0.3)  # 0-30%
            elif param in ['brightness', 'contrast']:
                new_value = np.clip(new_value, 0.0, 0.6)  # 0-60%
            elif param == 'noise':
                new_value = np.clip(new_value, 0.0, 0.15)  # 0-15%
            
            setattr(params, param, new_value)
        
        return params
    
    @staticmethod
    def crossover(parent1, parent2):
        """äº¤å‰ï¼ˆ2ç‚¹äº¤å‰ï¼‰"""
        child = AugmentationParams()
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¦ªã‹ã‚‰é¸æŠ
        for param in ['rotation', 'zoom', 'translation', 'brightness', 'contrast', 'noise']:
            if random.random() < 0.5:
                setattr(child, param, getattr(parent1, param))
            else:
                setattr(child, param, getattr(parent2, param))
        
        return child
    
    @staticmethod
    def random():
        """ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆ"""
        return AugmentationParams(
            rotation=random.uniform(0.0, 0.5),
            zoom=random.uniform(0.0, 0.4),
            translation=random.uniform(0.0, 0.3),
            brightness=random.uniform(0.0, 0.6),
            contrast=random.uniform(0.0, 0.6),
            noise=random.uniform(0.0, 0.15)
        )


def create_data_augmentation(params):
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½œæˆ"""
    layers = []
    
    if params.rotation > 0:
        layers.append(tf.keras.layers.RandomRotation(params.rotation))
    if params.zoom > 0:
        layers.append(tf.keras.layers.RandomZoom(params.zoom))
    if params.translation > 0:
        layers.append(tf.keras.layers.RandomTranslation(params.translation, params.translation))
    if params.brightness > 0:
        layers.append(tf.keras.layers.RandomBrightness(params.brightness))
    if params.contrast > 0:
        layers.append(tf.keras.layers.RandomContrast(params.contrast))
    if params.noise > 0:
        layers.append(tf.keras.layers.GaussianNoise(params.noise))
    
    return tf.keras.Sequential(layers) if layers else None


def evaluate_params(params, train_ds, test_ds, experiment_num, total_experiments):
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è©•ä¾¡"""
    print(f"\n{'='*70}")
    print(f"ğŸ§¬ å®Ÿé¨“ {experiment_num}/{total_experiments}")
    print(f"{'='*70}")
    print(f"  Rotation:     {params.rotation:.3f} (Â±{params.rotation*360:.1f}Â°)")
    print(f"  Zoom:         {params.zoom:.3f} (Â±{params.zoom*100:.1f}%)")
    print(f"  Translation:  {params.translation:.3f} (Â±{params.translation*100:.1f}%)")
    print(f"  Brightness:   {params.brightness:.3f} (Â±{params.brightness*100:.1f}%)")
    print(f"  Contrast:     {params.contrast:.3f} (Â±{params.contrast*100:.1f}%)")
    print(f"  Noise:        {params.noise:.3f}")
    print(f"{'='*70}\n")
    
    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ¬ã‚¤ãƒ¤ãƒ¼ä½œæˆ
    data_augmentation = create_data_augmentation(params)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
    train_dataset = train_ds
    if data_augmentation:
        train_dataset = train_ds.map(
            lambda x, y: (data_augmentation(x, training=True), y),
            num_parallel_calls=tf.data.AUTOTUNE
        )
    
    train_dataset = train_dataset.map(
        lambda x, y: (preprocessing_function(x), y),
        num_parallel_calls=tf.data.AUTOTUNE
    ).prefetch(tf.data.AUTOTUNE)
    
    test_dataset = test_ds.map(
        lambda x, y: (preprocessing_function(x), y),
        num_parallel_calls=tf.data.AUTOTUNE
    ).prefetch(tf.data.AUTOTUNE)
    
    # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    tf.keras.backend.clear_session()
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=(target_size, target_size, 3),
        include_top=False,
        weights="imagenet"
    )
    x = base_model.output
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    x = tf.keras.layers.Dense(3, activation="softmax")(x)
    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)
    
    model.compile(
        optimizer=optimizer_class(learning_rate=learning_rate),
        loss="categorical_crossentropy",
        metrics=["accuracy"]
    )
    
    # EarlyStopping
    callbacks = [
        tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=5,
            restore_best_weights=True,
            verbose=0
        )
    ]
    
    # å­¦ç¿’
    history = model.fit(
        train_dataset,
        validation_data=test_dataset,
        epochs=epochs,
        callbacks=callbacks,
        verbose=0
    )
    
    # æœ€é«˜ç²¾åº¦ã‚’å–å¾—
    best_val_accuracy = max(history.history['val_accuracy'])
    params.fitness = best_val_accuracy
    
    print(f"âœ… æ¤œè¨¼ç²¾åº¦: {best_val_accuracy*100:.2f}%\n")
    
    return best_val_accuracy


def simulated_annealing_genetic_algorithm(train_ds, test_ds, output_dir):
    """ç„¼ããªã¾ã—æ³• + éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æœ€é©åŒ–"""
    
    print("\n" + "="*70)
    print("ğŸ”¥ ç„¼ããªã¾ã—æ³• + éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æœ€é©åŒ–")
    print("="*70)
    print(f"é›†å›£ã‚µã‚¤ã‚º: {POPULATION_SIZE}")
    print(f"ä¸–ä»£æ•°: {GENERATIONS}")
    print(f"åˆæœŸæ¸©åº¦: {SIMULATED_ANNEALING_TEMP}")
    print(f"å†·å´ç‡: {COOLING_RATE}")
    print("="*70 + "\n")
    
    # åˆæœŸé›†å›£ã‚’ãƒ©ãƒ³ãƒ€ãƒ ç”Ÿæˆ
    population = [AugmentationParams.random() for _ in range(POPULATION_SIZE)]
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡ï¼ˆæ‹¡å¼µãªã—ï¼‰
    print("\nğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡ï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãªã—ï¼‰")
    baseline = AugmentationParams(0, 0, 0, 0, 0, 0)
    evaluate_params(baseline, train_ds, test_ds, 0, POPULATION_SIZE * GENERATIONS)
    
    best_overall = baseline
    history = []
    experiment_count = 1
    
    # ä¸–ä»£ãƒ«ãƒ¼ãƒ—
    for generation in range(GENERATIONS):
        print(f"\n{'#'*70}")
        print(f"ğŸ§¬ ç¬¬ {generation+1}/{GENERATIONS} ä¸–ä»£")
        print(f"{'#'*70}\n")
        
        # ç¾åœ¨ã®æ¸©åº¦ï¼ˆç„¼ããªã¾ã—æ³•ï¼‰
        temperature = SIMULATED_ANNEALING_TEMP * (COOLING_RATE ** generation)
        print(f"ğŸŒ¡ï¸ ç¾åœ¨ã®æ¸©åº¦: {temperature:.3f}\n")
        
        # å…¨å€‹ä½“ã‚’è©•ä¾¡
        for individual in population:
            if individual.fitness == 0.0:  # æœªè©•ä¾¡ã®å€‹ä½“ã®ã¿
                evaluate_params(individual, train_ds, test_ds, 
                              experiment_count, POPULATION_SIZE * GENERATIONS)
                experiment_count += 1
        
        # é©å¿œåº¦ã§ã‚½ãƒ¼ãƒˆ
        population.sort(key=lambda x: x.fitness, reverse=True)
        
        # æœ€è‰¯å€‹ä½“ã®æ›´æ–°
        if population[0].fitness > best_overall.fitness:
            best_overall = population[0]
            print(f"\nğŸ‰ æ–°è¨˜éŒ²! æ¤œè¨¼ç²¾åº¦: {best_overall.fitness*100:.2f}%")
        
        # ä¸–ä»£çµ±è¨ˆ
        avg_fitness = np.mean([ind.fitness for ind in population])
        history.append({
            'generation': generation + 1,
            'best_fitness': population[0].fitness,
            'avg_fitness': avg_fitness,
            'temperature': temperature,
            'best_params': population[0].to_dict()
        })
        
        print(f"\nğŸ“ˆ ç¬¬{generation+1}ä¸–ä»£ã®çµæœ:")
        print(f"  æœ€è‰¯: {population[0].fitness*100:.2f}%")
        print(f"  å¹³å‡: {avg_fitness*100:.2f}%")
        print(f"  æœ€æ‚ª: {population[-1].fitness*100:.2f}%")
        
        # æœ€çµ‚ä¸–ä»£ãªã‚‰çµ‚äº†
        if generation == GENERATIONS - 1:
            break
        
        # æ¬¡ä¸–ä»£ã®ç”Ÿæˆ
        new_population = []
        
        # ã‚¨ãƒªãƒ¼ãƒˆé¸æŠ
        new_population.extend(population[:ELITE_SIZE])
        
        # æ®‹ã‚Šã‚’äº¤å‰ã¨çªç„¶å¤‰ç•°ã§ç”Ÿæˆ
        while len(new_population) < POPULATION_SIZE:
            # ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆé¸æŠã§è¦ªã‚’é¸ã¶
            parent1 = max(random.sample(population, 3), key=lambda x: x.fitness)
            parent2 = max(random.sample(population, 3), key=lambda x: x.fitness)
            
            # äº¤å‰
            if random.random() < 0.7:  # 70%ã®ç¢ºç‡ã§äº¤å‰
                child = AugmentationParams.crossover(parent1, parent2)
            else:
                child = parent1
            
            # çªç„¶å¤‰ç•°ï¼ˆæ¸©åº¦ã«å¿œã˜ãŸå¤‰ç•°ï¼‰
            if random.random() < 0.8:  # 80%ã®ç¢ºç‡ã§çªç„¶å¤‰ç•°
                child = child.mutate(temperature)
            
            new_population.append(child)
        
        population = new_population
    
    # çµæœä¿å­˜
    results = {
        'best_params': best_overall.to_dict(),
        'baseline': baseline.to_dict(),
        'history': history,
        'total_experiments': experiment_count - 1
    }
    
    with open(os.path.join(output_dir, 'optimization_results.json'), 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    # ã‚°ãƒ©ãƒ•ä½œæˆ
    generations = [h['generation'] for h in history]
    best_fitness = [h['best_fitness'] * 100 for h in history]
    avg_fitness = [h['avg_fitness'] * 100 for h in history]
    
    plt.figure(figsize=(12, 6))
    plt.plot(generations, best_fitness, 'b-o', label='æœ€è‰¯å€‹ä½“', linewidth=2)
    plt.plot(generations, avg_fitness, 'r--s', label='å¹³å‡', linewidth=2)
    plt.axhline(y=baseline.fitness*100, color='g', linestyle=':', label='ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³', linewidth=2)
    plt.xlabel('ä¸–ä»£', fontsize=12)
    plt.ylabel('æ¤œè¨¼ç²¾åº¦ (%)', fontsize=12)
    plt.title('éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹æœ€é©åŒ–ã®é€²åŒ–', fontsize=14)
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'optimization_progress.png'), dpi=150)
    plt.close()
    
    return best_overall


def main():
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"smart_optimization_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)
    
    print("\n" + "="*70)
    print("ğŸš€ ã‚¹ãƒãƒ¼ãƒˆæœ€é©åŒ–æ¢ç´¢ã‚·ã‚¹ãƒ†ãƒ ")
    print("="*70)
    print(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    print("="*70 + "\n")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
    print("ğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...\n")
    
    # img_trainã¨img_testã‚’ç›´æ¥èª­ã¿è¾¼ã¿
    train_ds = tf.keras.utils.image_dataset_from_directory(
        "img_train",
        image_size=(target_size, target_size),
        batch_size=batch_size,
        label_mode="categorical",
        shuffle=True,
        seed=42
    )
    
    test_ds = tf.keras.utils.image_dataset_from_directory(
        "img_test",
        image_size=(target_size, target_size),
        batch_size=batch_size,
        label_mode="categorical",
        shuffle=False
    )
    
    # æœ€é©åŒ–å®Ÿè¡Œ
    best_params = simulated_annealing_genetic_algorithm(train_ds, test_ds, output_dir)
    
    # æœ€çµ‚çµæœ
    print("\n" + "="*70)
    print("ğŸ† æœ€é©åŒ–å®Œäº†!")
    print("="*70)
    print(f"\næœ€è‰¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    print(f"  Rotation:     {best_params.rotation:.3f} (Â±{best_params.rotation*360:.1f}Â°)")
    print(f"  Zoom:         {best_params.zoom:.3f} (Â±{best_params.zoom*100:.1f}%)")
    print(f"  Translation:  {best_params.translation:.3f} (Â±{best_params.translation*100:.1f}%)")
    print(f"  Brightness:   {best_params.brightness:.3f} (Â±{best_params.brightness*100:.1f}%)")
    print(f"  Contrast:     {best_params.contrast:.3f} (Â±{best_params.contrast*100:.1f}%)")
    print(f"  Noise:        {best_params.noise:.3f}")
    print(f"\næ¤œè¨¼ç²¾åº¦: {best_params.fitness*100:.2f}%")
    print(f"\nçµæœã¯ {output_dir}/ ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
