# 実験ログ・学習記録

## 📊 モデル開発履歴

### 実験 #1: ベースラインCNNモデル
**日付**: 初期開発  
**モデル**: カスタムCNN  
**結果**: 25.4%精度  
**学び**: 基本的なアーキテクチャでは不十分、転移学習が必要

---

### 実験 #2: VGG16転移学習
**日付**: 最近  
**モデル**: VGG16 + カスタムヘッド  
**ファイル**: `models/janken_model_safe.keras`

**設定**:
- 入力サイズ: 224x224
- バッチサイズ: 32
- エポック数: 20
- オプティマイザ: Adam(lr=0.001)

**結果**:
- 全体精度: **57.63%**
- グー再現率: 100% ✅
- チョキ再現率: 42.1% ⚠️
- パー再現率: 12.5% ❌

**分析**:
- 大幅な精度向上（+32.23%）
- 重大な問題: グー偏向（他のクラスもグーと誤認識）
- パー認識が極めて困難

**教訓**:
- 転移学習は効果的
- クラス不均衡問題への対策が必要
- データ拡張の強化が必要

---

### 実験 #3: EfficientNetB0改良モデル
**日付**: 最近  
**モデル**: EfficientNetB0 + 改良ヘッド  
**ファイル**: `models/janken_model_improved.keras`

**改良点**:
- より効率的なアーキテクチャ
- BatchNormalization追加
- 強化されたデータ拡張
- ファインチューニング（最後20層）

**設定**:
- 入力サイズ: 224x224
- バッチサイズ: 16
- エポック数: 25
- ファインチューニング: 最後20層

**結果**:
- 全体精度: **57.63%** (同等)
- グー再現率: 100% ✅
- チョキ再現率: 15.8% ⚠️
- パー再現率: **43.8%** ⬆️ (+31.3%)

**重要な発見**:
- パー認識が大幅改善 (12.5% → 43.8%)
- チョキ認識は低下 (42.1% → 15.8%)
- モデルサイズが効率化 (15M → 4.8M パラメータ)

**分析**:
- EfficientNetB0の効率性を確認
- パー認識改善は大きな進歩
- 全体のバランス調整が次の課題

---

### 計画中実験 #4: 強化版モデル
**目標**: 全体精度70%以上、各クラス再現率70%以上  
**ファイル**: `scripts/janken_train_enhanced.py`（準備済み）

**予定改良点**:
1. **Focal Loss**: 困難な例により多くの注意
2. **クラス重み付け**: 少数クラスに高い重み
3. **高度なデータ拡張**: より多様な変換
4. **段階的ファインチューニング**: より多くの層を最適化

**期待効果**:
- グー偏向問題の解決
- チョキ・パー認識の向上
- 全体的なバランス改善

## 🔍 詳細分析結果

### 混同行列分析（EfficientNetB0）
```
実際\予測    グー    チョキ    パー
グー         24      0        0     (完璧)
チョキ       16      3        0     (グーとの混同大)
パー          8      1        7     (改善傾向)
```

### 信頼度分析
- **グー予測**: 平均信頼度95.7% (過信傾向)
- **チョキ予測**: 平均信頼度14.9% (不安定)
- **パー予測**: 平均信頼度43.4% (適度)

### 失敗パターン分析
1. **チョキ→グー誤認識**: 指の形状の類似性
2. **パー→グー誤認識**: 背景や影の影響
3. **グー偏向**: モデルがグーを過度に選好

## 📈 性能推移

| 実験 | モデル | 全体精度 | グー | チョキ | パー | 主要改善点 |
|------|--------|----------|------|--------|------|------------|
| #1 | CNN | 25.4% | - | - | - | ベースライン |
| #2 | VGG16 | 57.6% | 100% | 42.1% | 12.5% | 転移学習効果 |
| #3 | EfficientNetB0 | 57.6% | 100% | 15.8% | 43.8% | パー認識改善 |
| #4 | 強化版（予定） | 70%+ | 85%+ | 70%+ | 70%+ | バランス調整 |

## 🎯 学習された重要ポイント

### 技術的学び
1. **転移学習の威力**: 25% → 57%の大幅改善
2. **アーキテクチャの重要性**: EfficientNetB0の効率性
3. **クラス不均衡**: 単純な精度向上では解決できない
4. **データ拡張**: 汎化性能向上に必須

### プロジェクト管理の学び
1. **段階的改善**: 一度に全てを変えず、段階的に改良
2. **詳細な記録**: 各実験の設定と結果を詳細に記録
3. **問題の特定**: 混同行列による詳細な分析が重要
4. **バックアップ**: 各段階でのモデル保存が重要

## 🚀 次のアクション項目

### 即座に実行
1. **強化版モデル訓練**: Focal Loss + クラス重み付け
2. **結果比較**: 全モデルの性能を統一的に評価

### 短期計画
3. **失敗例分析**: 誤分類された画像の詳細確認
4. **データセット拡張**: 困難な例の追加収集

### 中長期計画
5. **アンサンブル学習**: 複数モデルの組み合わせ
6. **リアルタイム予測**: 実用的なアプリケーション開発

---

**記録開始日**: 2025年11月4日  
**次回更新予定**: 強化版モデル実験完了後
